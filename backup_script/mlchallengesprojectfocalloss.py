# -*- coding: utf-8 -*-
"""MLChallengesProjectFocalLoss.ipynb

This is the jupyter notebook converted. This is a backup code not written in a clean way
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WigGqmqIBWd3UWPTLfbOYediB02Y04-j
"""

import random
import glob
from PIL import Image
import matplotlib
import shap
import numpy as np
import torch
import os
from collections import defaultdict, Counter
import pandas as pd
from torch import nn
from torch import optim
import torch.nn.functional as F
from torchvision import datasets, transforms, models
from torchvision.io import read_image
from torch.utils.data import Dataset, random_split, DataLoader
import torchvision.models as models
from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler
import albumentations as A
from albumentations.pytorch import ToTensorV2
import copy
import cv2
import sklearn
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sn
import pandas as pd

dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Transforms for augmentation pipeline
train_transforms = A.Compose(
    [
        A.CLAHE(),
        A.RandomRotate90(),
        A.Transpose(),
        A.ShiftScaleRotate(shift_limit=0.0625,
                           scale_limit=0.50, rotate_limit=45, p=.75),
        A.Blur(blur_limit=3),
        A.OpticalDistortion(),
        A.GridDistortion(),
        A.HueSaturationValue(),
        ToTensorV2(),
    ]
)

test_transforms = A.Compose(
    [
        ToTensorV2(),
    ]
)

# Pytorch weighted sampler


def weightedSampler(annotations_file):
    img_labels = pd.read_csv(
        annotations_file, delimiter=' ', header=None, names=['name', 'class'])
    labels = img_labels['class'].tolist()
    class_count = list(Counter(labels).values())
    num_samples = sum(class_count)
    class_weights = [num_samples/class_count[i]
                     for i in range(len(class_count))]
    weights = [class_weights[labels[i]] for i in range(int(num_samples))]
    print(class_weights)
    print(class_count)

    return weights, num_samples


def weightedSamplerTrain(train_labels):
    class_count = list(Counter(train_labels).values())
    num_samples = sum(class_count)
    class_weights = [num_samples/class_count[i]
                     for i in range(len(class_count))]
    weights = [class_weights[train_labels[i]] for i in range(int(num_samples))]
    return weights, num_samples

# Building Custom data loader


class hiriseImageDataset(Dataset):
    def __init__(self, annotations_file, img_dir, classmap_file,  transform=None, target_transform=None):
        self.img_labels = pd.read_csv(
            annotations_file, delimiter=' ', header=None)
        self.class_map = pd.read_csv(
            classmap_file, header=None, names=['class', 'name'])
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        image = cv2.imread(img_path)
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        label = self.img_labels.iloc[idx, 1]
        class_label_map = self.class_map.loc[self.class_map['class'] == label].name.item(
        )
        if self.transform:
            image = self.transform(image=gray_image)["image"]
        if self.target_transform:
            label = self.target_transform(label)
        return image, label, class_label_map


_, _, files = next(os.walk("../data/AllDatasets/train"))
file_count = len(files)
print(file_count)

train_dataset_subset = hiriseImageDataset('../data/AllDatasets/train_labels.txt', '../data/AllDatasets/train',
                                          '../data/landmarks_map-proj-v3_classmap.csv', transform=train_transforms)
valid_dataset_subset = hiriseImageDataset('../data/AllDatasets/val_labels.txt', '../data/AllDatasets/val',
                                          '../data/landmarks_map-proj-v3_classmap.csv', transform=test_transforms)
test_dataset = hiriseImageDataset('../data/AllDatasets/test_labels.txt', '../data/AllDatasets/test',
                                  '../data/landmarks_map-proj-v3_classmap.csv', transform=test_transforms)
# print(train_dataset[9878][1])
# #Splitting the dataset into train and valid
# num_train = len(train_dataset)
# indices = list(range(num_train))
# train_indices, val_indices = sklearn.model_selection.train_test_split(indices, test_size=0.33, random_state=42)
# train_dataset_subset = torch.utils.data.Subset(train_dataset, train_indices)
# valid_dataset_subset = torch.utils.data.Subset(valid_dataset, val_indices)

print(len(train_dataset_subset))
print(len(valid_dataset_subset))

# train_labels = [train_dataset_subset.__getitem__(i)[1] for i in range(0, train_dataset_subset.__len__())]

weights, num_samples = weightedSampler('../data/AllDatasets/train_labels.txt')

print(weights)

weighted_sampler = WeightedRandomSampler(weights=torch.DoubleTensor(
    weights), num_samples=int(num_samples), replacement=False)

print('Size of train dataset: ', len(train_dataset_subset))
print('Size of valid dataset: ', len(valid_dataset_subset))
# print('Size of train dataset: ', len(test_dataset))

print('The shape of tensor for 50th image in train dataset: ',
      train_dataset_subset[49][0].shape)
print('The label for 50th image in train dataset: ',
      train_dataset_subset[49][1])
print('The type of image is : ', train_dataset_subset[49][1].dtype)
print('The image plotted is as below : ')
plt.imshow(train_dataset_subset[49][0].T, cmap='gray', vmin=0, vmax=255)
plt.title(train_dataset_subset[49][2])
plt.show()

idx_to_class = pd.read_csv('../data/landmarks_map-proj-v3_classmap.csv',
                           index_col=0, header=None, squeeze=True).to_dict()

# visualizing augmentations


def visualize_augmentations(dataset, idx=0, samples=10, cols=5, random_img=False):
    dataset = copy.deepcopy(dataset)
    # dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])
    rows = samples // cols

    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 8))
    for i in range(samples):
        if random_img:
            idx = np.random.randint(1, len(dataset))
        image, lab, class_label_map = dataset[idx]
        ax.ravel()[i].imshow(image.T, cmap='gray', vmin=0, vmax=255)
        ax.ravel()[i].set_axis_off()
        ax.ravel()[i].set_title(idx_to_class[lab])
    plt.tight_layout(pad=1)
    plt.show()


visualize_augmentations(train_dataset_subset, np.random.randint(
    1, len(train_dataset_subset)), random_img=True)

BATCH_SIZE = 64
train_iterator = DataLoader(train_dataset_subset,  shuffle=True,
                            batch_size=BATCH_SIZE)

valid_iterator = DataLoader(valid_dataset_subset,
                            batch_size=BATCH_SIZE)


test_iterator = DataLoader(test_dataset,
                           batch_size=BATCH_SIZE)

test_gradcam_iterator = DataLoader(test_dataset, batch_size=1)

pretrained_model = models.resnet34(pretrained=True).to(dev)

print(pretrained_model)

for param in pretrained_model.parameters():
    param.requires_grad = False

IN_FEATURES = pretrained_model.fc.in_features
pretrained_model.fc = nn.Sequential(
    nn.Linear(IN_FEATURES, 128),
    nn.ReLU(inplace=True),
    nn.Linear(128, 8)).to(dev)
pretrained_model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(
    7, 7), stride=(2, 2), padding=(3, 3), bias=False) .to(dev)

weights = 1. / torch.tensor([45781, 168, 3664, 1762,
                            848, 855, 377, 1317]).to('cuda')
print(weights)
criterion = nn.CrossEntropyLoss(weight=weights)
optimizer = optim.Adam(pretrained_model.fc.parameters())


class FocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.logits = logits
        self.reduce = reduce

    def forward(self, inputs, targets):
        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)

        pt = torch.exp(-BCE_loss)
        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss

        if self.reduce:
            return torch.mean(F_loss)
        else:
            return F_loss


class FocalLoss(nn.modules.loss._WeightedLoss):
    def __init__(self, weight=None, gamma=2, reduction='mean'):
        super(FocalLoss, self).__init__(weight, reduction=reduction)
        self.gamma = gamma
        # weight parameter will act as the alpha parameter to balance class weights
        self.weight = weight

    def forward(self, input, target):

        ce_loss = F.cross_entropy(
            input, target, reduction=self.reduction, weight=self.weight)
        pt = torch.exp(-ce_loss)
        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()
        return focal_loss


criterion = FocalLoss()

datasets = {'train': train_dataset_subset, 'valid': valid_dataset_subset}

dataloaders = {'train': train_iterator, 'valid': valid_iterator}


def train_model(model, criterion, optimizer, num_epochs):
    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch+1, num_epochs))
        print('-' * 10)

        for phase in ['train', 'valid']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            for inputs, labels, _ in dataloaders[phase]:
                inputs = inputs.float().to(dev)
                labels = labels.to(dev)

                outputs = model(inputs)
                loss = criterion(outputs, labels)

                if phase == 'train':
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                _, preds = torch.max(outputs, 1)
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / len(datasets[phase])
            epoch_acc = running_corrects.double() / len(datasets[phase])

            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,
                                                        epoch_loss,
                                                        epoch_acc))
    return model

# uncomment the below lines to train the model
# model_trained = train_model(pretrained_model, criterion, optimizer, num_epochs=20)
# torch.save(model_trained.state_dict(), '/content/drive/MyDrive/MLChallengesProject/chkpts/weighted_random_sampler_run_weights_mar_resnet34_focal_loss.pth')


# The below line is used to load pretrained model
pretrained_model.load_state_dict(torch.load(
    '../chkpts/weighted_random_sampler_run_weights_mar_resnet34_focal_loss.pth'))

"""## Testing"""

images = glob.glob("../data/AllDatasets/test/*.jpg")
test_img_labels = pd.read_csv('../data/AllDatasets/test_labels.txt',
                              delimiter=' ', header=None, names=['name', 'class'])
test_images = test_img_labels['name'].sample(n=3, random_state=1).tolist()

test_imgs = []
transform_test = transforms.Compose([
    transforms.ToTensor()
])
for img_path in test_images:
    image = cv2.imread('../data/AllDatasets/test/'+img_path)
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    test_imgs.append(gray_image)

validation_batch = torch.stack([transform_test(img).to(dev)
                                for img in test_imgs])

pred_logits_tensor = pretrained_model(validation_batch)
pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()

fig, axs = plt.subplots(1, len(test_imgs), figsize=(20, 5))
for i, img in enumerate(test_imgs):
    ax = axs[i]
    ax.axis('off')
    ax.set_title("{:.0f}% Class 0, {:.0f}% 1, {:.0f}% 2, {:.0f}% 3, {:.0f}% 4, {:.0f}% 5, {:.0f}% 6, {:.0f}% 7 ".format(100*pred_probs[i, 0],
                                                                                                                        100 *
                                                                                                                        pred_probs[i, 1],
                                                                                                                        100 *
                                                                                                                        pred_probs[i, 2],
                                                                                                                        100 *
                                                                                                                        pred_probs[i, 3],
                                                                                                                        100 *
                                                                                                                        pred_probs[i, 4],
                                                                                                                        100 *
                                                                                                                        pred_probs[i, 5],
                                                                                                                        100 *
                                                                                                                        pred_probs[i, 6],
                                                                                                                        100*pred_probs[i, 7],))
    ax.imshow(img)


y_pred = []
y_true = []

# iterate over test data
for inputs, labels, _ in test_iterator:
    inputs = inputs.float().to(dev)
    labels = labels.to(dev)
    output = pretrained_model(inputs)  # Feed Network

    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()
    y_pred.extend(output)  # Save Prediction

    labels = labels.data.cpu().numpy()
    y_true.extend(labels)  # Save Truth

# constant for classes
classes = ('0', '1', '2', '3', '4',
           '5', '6', '7')

# Build confusion matrix
cf_matrix = confusion_matrix(y_true, y_pred)
df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1), index=[i for i in classes],
                     columns=[i for i in classes])
plt.figure(figsize=(12, 7))
sn.heatmap(df_cm, annot=True)
plt.savefig('output.png')


"""Using SHAP deep explainer"""

batch = next(iter(test_iterator))
images, _, _ = batch
images = images.view(-1, 1, 227, 227)

images.shape

background = images[5:65]
test_images = images[0:5]

background

test_images


test_images.shape

e = shap.DeepExplainer(pretrained_model, images.float().to(dev))
shap_values = e.shap_values(test_images)

shap_values

shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]
test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)

shap.image_plot(shap_numpy, -test_numpy)


"""## GradCAM"""


class GradCamModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.gradients = None
        self.tensorhook = []
        self.layerhook = []
        self.selected_out = None

        # PRETRAINED MODEL
        self.pretrained = pretrained_model
        self.layerhook.append(
            self.pretrained.layer4.register_forward_hook(self.forward_hook()))

        for p in self.pretrained.parameters():
            p.requires_grad = True

    def activations_hook(self, grad):
        self.gradients = grad

    def get_act_grads(self):
        return self.gradients

    def forward_hook(self):
        def hook(module, inp, out):
            self.selected_out = out
            self.tensorhook.append(out.register_hook(self.activations_hook))
        return hook

    def forward(self, x):
        out = self.pretrained(x)
        return out, self.selected_out


gcmodel = GradCamModel().to('cuda')

images_list = []

for img, _, _ in test_gradcam_iterator:
    images_list.append(img)

# test_img = '/content/AllDatasets/test/ESP_011425_1775_RED-0035-fv.jpg'

# from PIL import Image
# import torchvision.transforms as transforms
# image = Image.open('/content/AllDatasets/test/ESP_011425_1775_RED-0035-fv.jpg')
# transform = transforms.ToTensor()
# inpimg = transform(image).resize(1,1,227,227)

inpimg = images_list[2]

out, acts = gcmodel(inpimg.float().to('cuda'))
acts = acts.detach().cpu()
print(out.shape)
loss = nn.CrossEntropyLoss()(out, torch.from_numpy(np.array([2])).to('cuda'))
loss.backward()
grads = gcmodel.get_act_grads().detach().cpu()
pooled_grads = torch.mean(grads, dim=[0, 2, 3]).detach().cpu()
for i in range(acts.shape[1]):
    acts[:, i, :, :] *= pooled_grads[i]
heatmap_j = torch.mean(acts, dim=1).squeeze()
heatmap_j_max = heatmap_j.max(axis=0)[0]
heatmap_j /= heatmap_j_max
plt.matshow(heatmap_j.squeeze())

heatmap_j.shape


heatmap_j = heatmap_j.numpy()

cmap = matplotlib.cm.get_cmap('jet', 256)
heatmap_j2 = cmap(heatmap_j, alpha=0.2)

img = inpimg.numpy()

img = np.resize(img, (227, 227))

fig, axs = plt.subplots(1, 1, figsize=(5, 5))
axs.imshow(img)
axs.imshow(heatmap_j2)
plt.show()

heatmap_j = cv2.resize(heatmap_j, (227, 227))
heatmap = np.uint8(255 * heatmap_j)
heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
# superimposed_img = heatmap * 0.4 + img_rgb
# cv2.imwrite('./map.jpg', superimposed_img)

plt.imshow(heatmap_j)

plt.imshow(img_rgb)

plt.imshow(heatmap + img_rgb)
